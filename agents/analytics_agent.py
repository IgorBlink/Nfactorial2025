

import logging
import sys
import os
from typing import Dict, Any, Optional, List
from datetime import datetime
from pydantic import BaseModel, Field
import json
from openai import OpenAI

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from agents.base_agent import BaseA2AAgent
from utils.config import Config
from utils.a2a_client import A2ATask, TaskState

logger = logging.getLogger(__name__)


# Pydantic models for data validation
class AnalysisRequest(BaseModel):

    query: str = Field(..., description="The query to analyze")
    analysis_type: str = Field(default="general", description="Type of analysis to perform")
    depth: str = Field(default="standard", description="Depth of analysis: basic, standard, detailed")


class AnalysisResult(BaseModel):

    summary: str = Field(..., description="Summary of the analysis")
    key_points: List[str] = Field(default_factory=list, description="Key points from analysis")
    recommendations: List[str] = Field(default_factory=list, description="Recommendations based on analysis")
    confidence_score: float = Field(default=0.8, description="Confidence in the analysis")
    timestamp: datetime = Field(default_factory=datetime.now, description="When analysis was performed")


class DataInsight(BaseModel):
   
    insight: str = Field(..., description="The insight discovered")
    significance: str = Field(..., description="Why this insight is significant")
    evidence: List[str] = Field(default_factory=list, description="Evidence supporting the insight")


class AnalyticsAgent(BaseA2AAgent):
  
    
    def __init__(self, port: Optional[int] = None):
        
        if port is None:
            port = Config.ANALYTICS_AGENT_PORT
        
        super().__init__(
            name="AnalyticsAgent", 
            description="AI agent specialized in data analysis, insights generation, and reporting using structured analytics",
            port=port
        )
        
        # Validate configuration
        if not Config.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY is required for Analytics Agent")
        
        # Initialize OpenAI client
        try:
            self.client = OpenAI(
                api_key=Config.OPENAI_API_KEY,
                timeout=30.0
            )
        except Exception as e:
            logger.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ OpenAI ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°: {e}. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²ÑƒÑŽ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ.")
            # Fallback Ðº Ð±Ð¾Ð»ÐµÐµ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸
            import openai
            openai.api_key = Config.OPENAI_API_KEY
            self.client = OpenAI(api_key=Config.OPENAI_API_KEY)
        
        logger.info("Analytics Agent initialized with OpenAI")
    
    def process_task(self, task: A2ATask) -> A2ATask:
       
        try:
            # Extract user query
            user_input = self.extract_text_from_message(task.message)
            
            if not user_input:
                return self.create_error_response(
                    "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ Ñ‚ÐµÐºÑÑ‚ Ð¸Ð· ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ",
                    task
                )
            
            logger.info(f"Processing analytics query: {user_input}")
            
            # Parse request
            analysis_request = self._parse_analysis_request(user_input)
            
            # Perform analysis
            response = self._perform_analysis(analysis_request)
            
            # Create response
            return self.create_text_response(response, task)
            
        except Exception as e:
            logger.error(f"Error processing analytics task: {e}")
            return self.create_error_response(str(e), task)
    
    def _parse_analysis_request(self, user_input: str) -> AnalysisRequest:
        """Parse user input into analysis request."""
        # Determine analysis type
        analysis_type = "general"
        depth = "standard"
        
        input_lower = user_input.lower()
        
        if any(word in input_lower for word in ["Ð¾Ñ‚Ñ‡ÐµÑ‚", "report", "ÑÐ¾Ð·Ð´Ð°Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚"]):
            analysis_type = "report"
        elif any(word in input_lower for word in ["Ð¸Ð½ÑÐ°Ð¹Ñ‚", "insight", "Ð·Ð°ÐºÐ¾Ð½Ð¾Ð¼ÐµÑ€Ð½Ð¾ÑÑ‚ÑŒ"]):
            analysis_type = "insights"
        elif any(word in input_lower for word in ["Ð°Ð½Ð°Ð»Ð¸Ð· Ð´Ð°Ð½Ð½Ñ‹Ñ…", "data analysis"]):
            analysis_type = "data_analysis"
        
        if any(word in input_lower for word in ["Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½", "Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½", "Ð³Ð»ÑƒÐ±Ð¾Ðº"]):
            depth = "detailed"
        elif any(word in input_lower for word in ["ÐºÑ€Ð°Ñ‚Ðº", "Ð±Ð°Ð·Ð¾Ð²", "Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹"]):
            depth = "basic"
        
        return AnalysisRequest(
            query=user_input,
            analysis_type=analysis_type,
            depth=depth
        )
    
    def _perform_analysis(self, request: AnalysisRequest) -> str:
        """Perform analysis based on request type."""
        try:
            if request.analysis_type == "report":
                return self._generate_report(request)
            elif request.analysis_type == "insights":
                return self._extract_insights(request)
            elif request.analysis_type == "data_analysis":
                return self._analyze_data(request)
            else:
                return self._general_analysis(request)
                
        except Exception as e:
            logger.error(f"Error in analysis: {e}")
            return f"ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {str(e)}"
    
    def _analyze_data(self, request: AnalysisRequest) -> str:
      
        try:
            prompt = f"""
            Ð¢Ñ‹ - ÑÐºÑÐ¿ÐµÑ€Ñ‚ Ð¿Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…. ÐŸÑ€Ð¾Ð²ÐµÐ´Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð· ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°: {request.query}
            
            Ð“Ð»ÑƒÐ±Ð¸Ð½Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {request.depth}
            
            ÐŸÑ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²ÑŒ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð² JSON Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ ÑÐ¾ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¼Ð¸ Ð¿Ð¾Ð»ÑÐ¼Ð¸:
            - summary: ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ñ€ÐµÐ·ÑŽÐ¼Ðµ
            - key_points: ÑÐ¿Ð¸ÑÐ¾Ðº ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ñ… Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ð¾Ð² (Ð¼Ð°ÑÑÐ¸Ð² ÑÑ‚Ñ€Ð¾Ðº)
            - recommendations: Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ (Ð¼Ð°ÑÑÐ¸Ð² ÑÑ‚Ñ€Ð¾Ðº)
            - confidence_score: Ð¾Ñ†ÐµÐ½ÐºÐ° Ð´Ð¾ÑÑ‚Ð¾Ð²ÐµÑ€Ð½Ð¾ÑÑ‚Ð¸ (Ñ‡Ð¸ÑÐ»Ð¾ Ð¾Ñ‚ 0 Ð´Ð¾ 1)
            
            ÐžÑ‚Ð²ÐµÑ‚ÑŒ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð±ÐµÐ· Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°.
            """
            
            response = self.client.chat.completions.create(
                model=Config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "Ð¢Ñ‹ - Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…. Ð’ÑÐµÐ³Ð´Ð° Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ð¹ Ð² JSON Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1500
            )
            
            try:
                result_json = json.loads(response.choices[0].message.content)
                result = AnalysisResult(**result_json)
            except (json.JSONDecodeError, ValueError):
                # Fallback to simple parsing
                content = response.choices[0].message.content
                result = AnalysisResult(
                    summary=content[:200] + "..." if len(content) > 200 else content,
                    key_points=[content[:100] + "..."],
                    recommendations=["ÐÐ½Ð°Ð»Ð¸Ð· Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾"],
                    confidence_score=0.7
                )
            
            # Format the result nicely
            formatted_result = f"""
## ðŸ“Š Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…

### ÐšÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ñ€ÐµÐ·ÑŽÐ¼Ðµ:
{result.summary}

### ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ñ‹:
"""
            for i, point in enumerate(result.key_points, 1):
                formatted_result += f"{i}. {point}\n"
            
            if result.recommendations:
                formatted_result += "\n### Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸:\n"
                for i, rec in enumerate(result.recommendations, 1):
                    formatted_result += f"{i}. {rec}\n"
            
            formatted_result += f"\n### Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ Ð´Ð¾ÑÑ‚Ð¾Ð²ÐµÑ€Ð½Ð¾ÑÑ‚Ð¸: {result.confidence_score:.1%}"
            formatted_result += f"\n### Ð’Ñ€ÐµÐ¼Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {result.timestamp.strftime('%Y-%m-%d %H:%M:%S')}"
            
            return formatted_result
            
        except Exception as e:
            logger.error(f"Error in data analysis: {e}")
            return f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ…: {str(e)}"
    
    def _generate_report(self, request: AnalysisRequest) -> str:
      
        try:
            prompt = f"""
            Ð¡Ð¾Ð·Ð´Ð°Ð¹ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°:
            {request.query}
            
            ÐžÑ‚Ñ‡ÐµÑ‚ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ‚ÑŒ:
            - Ð˜ÑÐ¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ñ€ÐµÐ·ÑŽÐ¼Ðµ
            - Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·
            - Ð’Ñ‹Ð²Ð¾Ð´Ñ‹ Ð¸ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸
            - Ð¡Ð»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ðµ ÑˆÐ°Ð³Ð¸
            
            Ð“Ð»ÑƒÐ±Ð¸Ð½Ð° Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {request.depth}
            """
            
            response = self.client.chat.completions.create(
                model=Config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "Ð¢Ñ‹ - ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚ Ð¿Ð¾ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸ÑŽ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð²."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000
            )
            
            report = response.choices[0].message.content
            return f"## ðŸ“‹ ÐÐ½Ð°Ð»Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚\n\n{report}"
            
        except Exception as e:
            logger.error(f"Error generating report: {e}")
            return f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°: {str(e)}"
    
    def _extract_insights(self, request: AnalysisRequest) -> str:
      
        try:
            prompt = f"""
            Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ñ‹ Ð¸Ð· ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°: {request.query}
            
            ÐÐ°Ð¹Ð´Ð¸:
            - Ð¡ÐºÑ€Ñ‹Ñ‚Ñ‹Ðµ Ð·Ð°ÐºÐ¾Ð½Ð¾Ð¼ÐµÑ€Ð½Ð¾ÑÑ‚Ð¸
            - Ð’Ð°Ð¶Ð½Ñ‹Ðµ Ñ‚ÐµÐ½Ð´ÐµÐ½Ñ†Ð¸Ð¸  
            - ÐÐµÐ¾Ð¶Ð¸Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð²Ñ‹Ð²Ð¾Ð´Ñ‹
            - ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¿Ñ€Ð¸Ð¼ÐµÐ½Ð¸Ð¼Ñ‹Ðµ Ð½Ð°Ñ…Ð¾Ð´ÐºÐ¸
            
            ÐŸÑ€ÐµÐ´ÑÑ‚Ð°Ð²ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð² Ð²Ð¸Ð´Ðµ ÑÐ¿Ð¸ÑÐºÐ° Ð¸Ð½ÑÐ°Ð¹Ñ‚Ð¾Ð², Ð³Ð´Ðµ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ð¸Ð½ÑÐ°Ð¹Ñ‚ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚:
            1. ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ð°
            2. Ð•Ð³Ð¾ Ð·Ð½Ð°Ñ‡Ð¸Ð¼Ð¾ÑÑ‚ÑŒ
            3. ÐžÐ±Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ð¸Ðµ
            """
            
            response = self.client.chat.completions.create(
                model=Config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "Ð¢Ñ‹ - Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ðº Ð¿Ð¾ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸ÑŽ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ð¾Ð² Ð¸Ð· Ð´Ð°Ð½Ð½Ñ‹Ñ…."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.8,
                max_tokens=1500
            )
            
            insights_text = response.choices[0].message.content
            
            return f"## ðŸ’¡ ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ñ‹\n\n{insights_text}"
            
        except Exception as e:
            logger.error(f"Error extracting insights: {e}")
            return f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ð¸ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ð¾Ð²: {str(e)}"
    
    def _general_analysis(self, request: AnalysisRequest) -> str:
  
        try:
            response = self.client.chat.completions.create(
                model=Config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "Ð¢Ñ‹ - ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ðº. ÐŸÑ€Ð¾Ð²Ð¾Ð´Ð¸ Ñ‚Ñ‰Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²."},
                    {"role": "user", "content": f"ÐŸÑ€Ð¾Ð²ÐµÐ´Ð¸ Ð¾Ð±Ñ‰Ð¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°: {request.query}"}
                ],
                temperature=0.7,
                max_tokens=1500
            )
            
            analysis = response.choices[0].message.content
            
            return f"""
## ðŸ” ÐžÐ±Ñ‰Ð¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·

{analysis}
"""
        except Exception as e:
            logger.error(f"Error in general analysis: {e}")
            return f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ‰ÐµÐ¼ Ð°Ð½Ð°Ð»Ð¸Ð·Ðµ: {str(e)}"
    
    def get_capabilities(self) -> Dict[str, Any]:
      
        return {
            "analysis_types": [
                "data_analysis",
                "report_generation",
                "insight_extraction",
                "general_analysis"
            ],
            "depth_levels": ["basic", "standard", "detailed"],
            "output_formats": ["structured", "report", "insights"],
            "framework": "OpenAI Direct",
            "model": Config.OPENAI_MODEL
        }


def main():

    try:
        # Validate configuration
        Config.validate()
        
        # Create and run agent
        agent = AnalyticsAgent()
        agent.run(debug=True)
        
    except KeyboardInterrupt:
        logger.info("Analytics Agent stopped by user")
    except Exception as e:
        logger.error(f"Failed to start Analytics Agent: {e}")
        raise


if __name__ == "__main__":
    main() 