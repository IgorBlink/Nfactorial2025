

import logging
import sys
import os
from typing import Dict, Any, Optional, List
from datetime import datetime
from pydantic import BaseModel, Field
import json
from openai import OpenAI

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from agents.base_agent import BaseA2AAgent
from utils.config import Config
from utils.a2a_client import A2ATask, TaskState

logger = logging.getLogger(__name__)


# Pydantic models for data validation
class AnalysisRequest(BaseModel):

    query: str = Field(..., description="The query to analyze")
    analysis_type: str = Field(default="general", description="Type of analysis to perform")
    depth: str = Field(default="standard", description="Depth of analysis: basic, standard, detailed")


class AnalysisResult(BaseModel):

    summary: str = Field(..., description="Summary of the analysis")
    key_points: List[str] = Field(default_factory=list, description="Key points from analysis")
    recommendations: List[str] = Field(default_factory=list, description="Recommendations based on analysis")
    confidence_score: float = Field(default=0.8, description="Confidence in the analysis")
    timestamp: datetime = Field(default_factory=datetime.now, description="When analysis was performed")


class DataInsight(BaseModel):
   
    insight: str = Field(..., description="The insight discovered")
    significance: str = Field(..., description="Why this insight is significant")
    evidence: List[str] = Field(default_factory=list, description="Evidence supporting the insight")


class AnalyticsAgent(BaseA2AAgent):
  
    
    def __init__(self, port: Optional[int] = None):
        
        if port is None:
            port = Config.ANALYTICS_AGENT_PORT
        
        super().__init__(
            name="AnalyticsAgent", 
            description="AI agent specialized in data analysis, insights generation, and reporting using structured analytics",
            port=port
        )
        
        # Validate configuration
        if not Config.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY is required for Analytics Agent")
        
        # Initialize OpenAI client
        try:
            self.client = OpenAI(
                api_key=Config.OPENAI_API_KEY,
                timeout=30.0
            )
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é.")
            # Fallback –∫ –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            import openai
            openai.api_key = Config.OPENAI_API_KEY
            self.client = OpenAI(api_key=Config.OPENAI_API_KEY)
        
        logger.info("Analytics Agent initialized with OpenAI")
    
    def process_task(self, task: A2ATask) -> A2ATask:
       
        try:
            # Extract user query
            user_input = self.extract_text_from_message(task.message)
            
            if not user_input:
                return self.create_error_response(
                    "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è",
                    task
                )
            
            logger.info(f"Processing analytics query: {user_input}")
            
            # Parse request
            analysis_request = self._parse_analysis_request(user_input)
            
            # Perform analysis
            response = self._perform_analysis(analysis_request)
            
            # Create response
            return self.create_text_response(response, task)
            
        except Exception as e:
            logger.error(f"Error processing analytics task: {e}")
            return self.create_error_response(str(e), task)
    
    def _parse_analysis_request(self, user_input: str) -> AnalysisRequest:
        """Parse user input into analysis request."""
        # Determine analysis type
        analysis_type = "general"
        depth = "standard"
        
        input_lower = user_input.lower()
        
        if any(word in input_lower for word in ["–æ—Ç—á–µ—Ç", "report", "—Å–æ–∑–¥–∞–π –æ—Ç—á–µ—Ç"]):
            analysis_type = "report"
        elif any(word in input_lower for word in ["–∏–Ω—Å–∞–π—Ç", "insight", "–∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç—å"]):
            analysis_type = "insights"
        elif any(word in input_lower for word in ["–∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö", "data analysis"]):
            analysis_type = "data_analysis"
        
        if any(word in input_lower for word in ["–¥–µ—Ç–∞–ª—å–Ω", "–ø–æ–¥—Ä–æ–±–Ω", "–≥–ª—É–±–æ–∫"]):
            depth = "detailed"
        elif any(word in input_lower for word in ["–∫—Ä–∞—Ç–∫", "–±–∞–∑–æ–≤", "–ø—Ä–æ—Å—Ç–æ–π"]):
            depth = "basic"
        
        return AnalysisRequest(
            query=user_input,
            analysis_type=analysis_type,
            depth=depth
        )
    
    def _perform_analysis(self, request: AnalysisRequest) -> str:
        """Perform analysis based on request type."""
        try:
            if request.analysis_type == "report":
                return self._generate_report(request)
            elif request.analysis_type == "insights":
                return self._extract_insights(request)
            elif request.analysis_type == "data_analysis":
                return self._analyze_data(request)
            else:
                return self._general_analysis(request)
                
        except Exception as e:
            logger.error(f"Error in analysis: {e}")
            return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"
    
    def _analyze_data(self, request: AnalysisRequest) -> str:
      
        try:
            prompt = f"""
            –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–≤–µ–¥–∏ –∞–Ω–∞–ª–∏–∑ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {request.query}
            
            –ì–ª—É–±–∏–Ω–∞ –∞–Ω–∞–ª–∏–∑–∞: {request.depth}
            
            –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –ø–æ–ª—è–º–∏:
            - summary: –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ
            - key_points: —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤ (–º–∞—Å—Å–∏–≤ —Å—Ç—Ä–æ–∫)
            - recommendations: —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–º–∞—Å—Å–∏–≤ —Å—Ç—Ä–æ–∫)
            - confidence_score: –æ—Ü–µ–Ω–∫–∞ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ (—á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 1)
            
            –û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
            """
            
            response = self.client.chat.completions.create(
                model=Config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "–¢—ã - –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö. –í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1500
            )
            
            try:
                result_json = json.loads(response.choices[0].message.content)
                result = AnalysisResult(**result_json)
            except (json.JSONDecodeError, ValueError):
                # Fallback to simple parsing
                content = response.choices[0].message.content
                result = AnalysisResult(
                    summary=content[:200] + "..." if len(content) > 200 else content,
                    key_points=[content[:100] + "..."],
                    recommendations=["–ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ"],
                    confidence_score=0.7
                )
            
            # Format the result nicely
            formatted_result = f"""
## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö

### –ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ:
{result.summary}

### –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:
"""
            for i, point in enumerate(result.key_points, 1):
                formatted_result += f"{i}. {point}\n"
            
            if result.recommendations:
                formatted_result += "\n### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\n"
                for i, rec in enumerate(result.recommendations, 1):
                    formatted_result += f"{i}. {rec}\n"
            
            formatted_result += f"\n### –£—Ä–æ–≤–µ–Ω—å –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏: {result.confidence_score:.1%}"
            formatted_result += f"\n### –í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {result.timestamp.strftime('%Y-%m-%d %H:%M:%S')}"
            
            return formatted_result
            
        except Exception as e:
            logger.error(f"Error in data analysis: {e}")
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}"
    
    def _generate_report(self, request: AnalysisRequest) -> str:
      
        try:
            prompt = f"""
            –°–æ–∑–¥–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞:
            {request.query}
            
            –û—Ç—á–µ—Ç –¥–æ–ª–∂–µ–Ω –≤–∫–ª—é—á–∞—Ç—å:
            - –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–µ–∑—é–º–µ
            - –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            - –í—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            - –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏
            
            –ì–ª—É–±–∏–Ω–∞ –∞–Ω–∞–ª–∏–∑–∞: {request.depth}
            """
            
            response = self.client.chat.completions.create(
                model=Config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "–¢—ã - —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç—á–µ—Ç–æ–≤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000
            )
            
            report = response.choices[0].message.content
            return f"## üìã –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç\n\n{report}"
            
        except Exception as e:
            logger.error(f"Error generating report: {e}")
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –æ—Ç—á–µ—Ç–∞: {str(e)}"
    
    def _extract_insights(self, request: AnalysisRequest) -> str:
      
        try:
            prompt = f"""
            –ò–∑–≤–ª–µ–∫–∏ –∫–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã –∏–∑ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {request.query}
            
            –ù–∞–π–¥–∏:
            - –°–∫—Ä—ã—Ç—ã–µ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏
            - –í–∞–∂–Ω—ã–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏  
            - –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ –≤—ã–≤–æ–¥—ã
            - –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏–º–µ–Ω–∏–º—ã–µ –Ω–∞—Ö–æ–¥–∫–∏
            
            –ü—Ä–µ–¥—Å—Ç–∞–≤—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–∞ –∏–Ω—Å–∞–π—Ç–æ–≤, –≥–¥–µ –∫–∞–∂–¥—ã–π –∏–Ω—Å–∞–π—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç:
            1. –û–ø–∏—Å–∞–Ω–∏–µ –∏–Ω—Å–∞–π—Ç–∞
            2. –ï–≥–æ –∑–Ω–∞—á–∏–º–æ—Å—Ç—å
            3. –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ
            """
            
            response = self.client.chat.completions.create(
                model=Config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "–¢—ã - –∞–Ω–∞–ª–∏—Ç–∏–∫ –ø–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—é –∏–Ω—Å–∞–π—Ç–æ–≤ –∏–∑ –¥–∞–Ω–Ω—ã—Ö."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.8,
                max_tokens=1500
            )
            
            insights_text = response.choices[0].message.content
            
            return f"## üí° –ö–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã\n\n{insights_text}"
            
        except Exception as e:
            logger.error(f"Error extracting insights: {e}")
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∏–Ω—Å–∞–π—Ç–æ–≤: {str(e)}"
    
    def _general_analysis(self, request: AnalysisRequest) -> str:
  
        try:
            response = self.client.chat.completions.create(
                model=Config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "–¢—ã - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫. –ü—Ä–æ–≤–æ–¥–∏ —Ç—â–∞—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–æ–≤."},
                    {"role": "user", "content": f"–ü—Ä–æ–≤–µ–¥–∏ –æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {request.query}"}
                ],
                temperature=0.7,
                max_tokens=1500
            )
            
            analysis = response.choices[0].message.content
            
            return f"""
## üîç –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑

{analysis}
"""
        except Exception as e:
            logger.error(f"Error in general analysis: {e}")
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—â–µ–º –∞–Ω–∞–ª–∏–∑–µ: {str(e)}"
    
    def get_capabilities(self) -> Dict[str, Any]:
      
        return {
            "analysis_types": [
                "data_analysis",
                "report_generation",
                "insight_extraction",
                "general_analysis"
            ],
            "depth_levels": ["basic", "standard", "detailed"],
            "output_formats": ["structured", "report", "insights"],
            "framework": "OpenAI Direct",
            "model": Config.OPENAI_MODEL
        }


def main():

    try:
        # Validate configuration
        Config.validate()
        
        # Create and run agent
        agent = AnalyticsAgent()
        agent.run(debug=True)
        
    except KeyboardInterrupt:
        logger.info("Analytics Agent stopped by user")
    except Exception as e:
        logger.error(f"Failed to start Analytics Agent: {e}")
        raise


if __name__ == "__main__":
    main() 